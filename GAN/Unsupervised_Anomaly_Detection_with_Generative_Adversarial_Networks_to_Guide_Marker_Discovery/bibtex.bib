@InProceedings{10.1007/978-3-319-59050-9_12,
author="Schlegl, Thomas
and Seeb{\"o}ck, Philipp
and Waldstein, Sebastian M.
and Schmidt-Erfurth, Ursula
and Langs, Georg",
editor="Niethammer, Marc
and Styner, Martin
and Aylward, Stephen
and Zhu, Hongtu
and Oguz, Ipek
and Yap, Pew-Thian
and Shen, Dinggang",
title="Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery",
booktitle="Information Processing in Medical Imaging",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="146--157",
abstract="Obtaining models that capture imaging markers relevant forÂ disease progression and treatment monitoring is challenging. Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection. High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches. Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers. We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution. Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.",
isbn="978-3-319-59050-9"
}

