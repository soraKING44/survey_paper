# Simultaneous Estimation of Self-position and Word from Noisy Utterances and Sensory Information
# https://www.sciencedirect.com/science/article/pii/S2405896316321188
@article{TANIGUCHI2016221,
title = "Simultaneous Estimation of Self-position and Word from Noisy Utterances and Sensory Information",
journal = "IFAC-PapersOnLine",
volume = "49",
number = "19",
pages = "221 - 226",
year = "2016",
note = "13th IFAC Symposium on Analysis, Design, and Evaluation ofHuman-Machine Systems HMS 2016",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.10.528",
url = "http://www.sciencedirect.com/science/article/pii/S2405896316321188",
author = "Akira Taniguchi and Tadahiro Taniguchi and Tetsunari Inamura",
keywords = "ambiguous speech recognition, lexical acquisition, self-localization",
abstract = "Abstract:
In this paper, we propose a novel learning method that can simultaneously estimate the self-position of a robot and place names. The robot moves in a room environment and performs probabilistic self-localization based on noisy sensory information. Speech recognition results include the uncertainty of phonemes or syllables, because the robot does not have lexical knowledge in advance. The purpose of this study is to reduce the uncertainty of both self-position and speech recognition using knowledge about place names, which is obtained from human speech. The proposed method integrates ambiguous speech recognition results with the self-localization method, i.e., Monte Carlo localization, using a Bayesian approach. Probability distributions over places and the speech recognition error are modeled using the proposed method. We implemented the proposed method in SIGVerse, which is a simulation environment. Experimental results showed that the robot can acquire the names of several places and use this knowledge to reduce the uncertainty of estimation in its position in a self-localization task. In addition, we evaluated the performance of the lexical acquisition task for the names of places and showed its effectiveness. Results showed that the robot could acquire spatial concepts by integrating noisy information from sensors and speech."
}