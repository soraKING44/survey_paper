# Omnidirectional CNN for Visual Place Recognition and Navigation
# https://ieeexplore.ieee.org/document/8463173
@INPROCEEDINGS{8463173, 
author={T. {Wang} and H. {Huang} and J. {Lin} and C. {Hu} and K. {Zeng} and M. {Sun}}, 
booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, 
title={Omnidirectional CNN for Visual Place Recognition and Navigation}, 
year={2018}, 
volume={}, 
number={}, 
pages={2341-2348}, 
keywords={cameras;feature extraction;feedforward neural nets;image matching;image retrieval;learning (artificial intelligence);mobile robots;object recognition;pose estimation;robot vision;visual place recognition;place exemplars;recognition method;omnidirectional cameras;visual input;matched place exemplar;closest place exemplar;relative distance;retrieved closest place;omnidirectional view;powerful O-CNN;Omnidirectional CNN;virtual world datasets;real-world datasets;omnidirectional convolutional neural network;camera pose variation;Visualization;Navigation;Robots;Measurement;Cameras;Feature extraction;Task analysis}, 
doi={10.1109/ICRA.2018.8463173}, 
ISSN={2577-087X}, 
month={May},}